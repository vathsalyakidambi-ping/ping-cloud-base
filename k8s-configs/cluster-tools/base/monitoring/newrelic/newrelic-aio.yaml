# This file contains all Newrelic-related manifests combined in one yaml. 
# It shouldn't be listed in kustomization.yaml

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nri-bundle-nri-metadata-injection-admission
  annotations:
    argocd.argoproj.io/hook: Sync,PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation,HookSucceeded
  labels:
    nri-bundle.version: 4.5.8
    app: nri-metadata-injection-admission
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-metadata-injection
    app.kubernetes.io/version: 1.7.0
rules:
  - apiGroups:
      - admissionregistration.k8s.io
    resources:
      - mutatingwebhookconfigurations
    verbs:
      - get
      - update

  - apiGroups: [""]
    resources:
      - secrets
    verbs: ["get", "create", "patch"]

  - apiGroups: ['policy']
    resources: ['podsecuritypolicies']
    verbs: ['use']
    resourceNames:
    - nri-bundle-nri-metadata-injection-admission

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-newrelic-infrastructure
rules:
  - apiGroups: [""]
    resources:
      - "nodes"
      - "nodes/metrics"
      - "nodes/stats"
      - "nodes/proxy"
      - "pods"
      - "services"
    verbs: ["get", "list"]

  - apiGroups: [ "" ]
    resources:
      - "endpoints"
      - "services"
      - "nodes"
    verbs: [ "get", "list", "watch" ]

  - apiGroups: [""]
    resources:
    - secrets
    verbs: ["get", "list", "watch", "create"]

  - apiGroups: ["batch"]
    resources:
    - jobs
    verbs: ["get", "list", "watch"]

  - nonResourceURLs: ["/metrics"]
    verbs: ["get"]

---
# Source: nri-bundle/charts/kube-state-metrics/templates/role.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/name: kube-state-metrics
    helm.sh/chart: kube-state-metrics-2.13.2
    app.kubernetes.io/instance: nri-bundle
  name: nri-bundle-kube-state-metrics
rules:

- apiGroups: ["certificates.k8s.io"]
  resources:
  - certificatesigningrequests
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - configmaps
  verbs: ["list", "watch"]

- apiGroups: ["batch"]
  resources:
  - cronjobs
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - daemonsets
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - deployments
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - endpoints
  verbs: ["list", "watch"]

- apiGroups: ["autoscaling"]
  resources:
  - horizontalpodautoscalers
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "networking.k8s.io"]
  resources:
  - ingresses
  verbs: ["list", "watch"]

- apiGroups: ["batch"]
  resources:
  - jobs
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - limitranges
  verbs: ["list", "watch"]

- apiGroups: ["admissionregistration.k8s.io"]
  resources:
    - mutatingwebhookconfigurations
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - namespaces
  verbs: ["list", "watch"]

- apiGroups: ["networking.k8s.io"]
  resources:
  - networkpolicies
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - nodes
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - persistentvolumeclaims
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - persistentvolumes
  verbs: ["list", "watch"]

- apiGroups: ["policy"]
  resources:
    - poddisruptionbudgets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - pods
  verbs: ["list", "watch"]

- apiGroups: ["extensions", "apps"]
  resources:
  - replicasets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - replicationcontrollers
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - resourcequotas
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - secrets
  verbs: ["list", "watch"]

- apiGroups: [""]
  resources:
  - services
  verbs: ["list", "watch"]

- apiGroups: ["apps"]
  resources:
  - statefulsets
  verbs: ["list", "watch"]

- apiGroups: ["storage.k8s.io"]
  resources:
    - storageclasses
  verbs: ["list", "watch"]

- apiGroups: ["admissionregistration.k8s.io"]
  resources:
    - validatingwebhookconfigurations
  verbs: ["list", "watch"]

- apiGroups: ["storage.k8s.io"]
  resources:
    - volumeattachments
  verbs: ["list", "watch"]

---
# Source: nri-bundle/charts/nri-kube-events/templates/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-kube-events
    app.kubernetes.io/version: 1.8.0
    helm.sh/chart: nri-kube-events-2.2.4
  name: nri-bundle-nri-kube-events
rules:
  - apiGroups: [""]
    resources: ["events"]
    verbs: ["get", "watch", "list"]

  - apiGroups: ["batch"]
    resources:
    - jobs
    verbs: ["get", "list", "watch"]

  - apiGroups: [""]
    resources:
    - secrets
    verbs: ["get"]

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/controlplane/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-controlplane
rules:
  - apiGroups: [""]
    resources:
      - "nodes/metrics"
      - "nodes/stats"
      - "nodes/proxy"
    verbs: ["get", "list"]
  - apiGroups: [ "" ]
    resources:
      - "pods"
      - "nodes"
    verbs: [ "get", "list", "watch" ]
  - nonResourceURLs: ["/metrics"]
    verbs: ["get", "head"]

---
# Source: nri-bundle/charts/nri-prometheus/templates/clusterrole.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRole
metadata:
  name: nri-bundle-nri-prometheus
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-prometheus
    app.kubernetes.io/version: 2.16.1
    helm.sh/chart: nri-prometheus-2.1.5
rules:
- apiGroups: [""]
  resources:
    - "nodes"
    - "nodes/metrics"
    - "nodes/stats"
    - "nodes/proxy"
    - "pods"
    - "services"
    - "endpoints"
  verbs: ["get", "list", "watch"]

- apiGroups: ["batch"]
  resources:
  - jobs
  verbs: ["get", "list", "watch"]
- apiGroups: [""]
  resources:
  - secrets
  verbs: ["get"]

- nonResourceURLs:
  - /metrics
  verbs:
  - get
---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nri-bundle-nri-metadata-injection-admission
  annotations:
    argocd.argoproj.io/hook: Sync,PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation,HookSucceeded
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-metadata-injection
    app.kubernetes.io/version: 1.7.0
    helm.sh/chart: nri-metadata-injection-3.0.4
    app: nri-metadata-injection-admission
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-nri-metadata-injection-admission
subjects:
  - kind: ServiceAccount
    name: nri-bundle-nri-metadata-injection-admission
    namespace: newrelic

---
# Source: nri-bundle/charts/kube-state-metrics/templates/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/name: kube-state-metrics
    helm.sh/chart: kube-state-metrics-2.13.2
    app.kubernetes.io/instance: nri-bundle
  name: nri-bundle-kube-state-metrics
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-kube-state-metrics
subjects:
- kind: ServiceAccount
  name: nri-bundle-kube-state-metrics
  namespace: newrelic

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-newrelic-infrastructure
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-newrelic-infrastructure
subjects:
- kind: ServiceAccount
  name: nri-bundle-newrelic-infrastructure
  namespace: newrelic

---
# Source: nri-bundle/charts/nri-kube-events/templates/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-kube-events
    app.kubernetes.io/version: 1.8.0
    helm.sh/chart: nri-kube-events-2.2.4
  name: nri-bundle-nri-kube-events
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-nri-kube-events
subjects:
- kind: ServiceAccount
  name: nri-bundle-nri-kube-events
  namespace: newrelic

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/controlplane/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-controlplane
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-nrk8s-controlplane
subjects:
  - kind: ServiceAccount
    name: nri-bundle-newrelic-infrastructure-controlplane
    namespace: newrelic

---
# Source: nri-bundle/charts/nri-prometheus/templates/clusterrolebinding.yaml

apiVersion: rbac.authorization.k8s.io/v1
kind: ClusterRoleBinding
metadata:
  name: nri-bundle-nri-prometheus
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-prometheus
    app.kubernetes.io/version: 2.16.1
    helm.sh/chart: nri-prometheus-2.1.5
roleRef:
  apiGroup: rbac.authorization.k8s.io
  kind: ClusterRole
  name: nri-bundle-nri-prometheus
subjects:
- kind: ServiceAccount
  name: nri-bundle-nri-prometheus
  namespace: newrelic
---
# Source: nri-bundle/charts/nri-kube-events/templates/configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-kube-events
    app.kubernetes.io/version: 1.8.0
    helm.sh/chart: nri-kube-events-2.2.4
  name: nri-bundle-nri-kube-events-config
  namespace: newrelic
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  config.yaml: |-
    sinks:
    - name: newRelicInfra
      config:
        agentEndpoint: http://localhost:8001/v1/data
        clusterName: k8s-cluster-name
        agentHTTPTimeout: 30s

---
# Source: nri-bundle/charts/nri-prometheus/templates/configmap.yaml

kind: ConfigMap
metadata:
  name: nri-bundle-nri-prometheus-config
  namespace: newrelic
  labels:
    app.kubernetes.io/name: nri-prometheus
    helm.sh/chart: nri-prometheus-1.10.0
    app.kubernetes.io/version: "2.9.0"
apiVersion: v1
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  config.yaml: |
    cluster_name: k8s-cluster-name
    audit: false
    insecure_skip_verify: false
    require_scrape_enabled_label_for_nodes: true
    scrape_enabled_label: prometheus.io/scrape
    scrape_endpoints: false
    scrape_services: true
    transformations:
    - description: Low data mode defaults
      ignore_metrics:
      - prefixes:
        - kube_
        - container_
        - machine_
        - cadvisor_
    verbose: false

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/controlplane/agent-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-agent-controlplane
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  newrelic-infra.yml: |-
    # This is the configuration file for the infrastructure agent. See:
    # https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/
    custom_attributes:
      clusterName: k8s-cluster-name
    http_server_enabled: true
    http_server_port: 8001
    is_forward_only: true

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/controlplane/scraper-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-controlplane
  namespace: newrelic
data:
  nri-kubernetes.yml: |-
    interval: 15s
    controlPlane:
      retries: 3
      timeout: 10s
      enabled: true
      etcd:
        autodiscover:
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:4001
          - url: http://localhost:2381
          matchNode: true
          namespace: kube-system
          selector: tier=control-plane,component=etcd
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:4001
          matchNode: true
          namespace: kube-system
          selector: k8s-app=etcd-manager-main
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:4001
          matchNode: true
          namespace: kube-system
          selector: k8s-app=etcd
        enabled: true
      scheduler:
        autodiscover:
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10259
          matchNode: true
          namespace: kube-system
          selector: tier=control-plane,component=kube-scheduler
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10259
          matchNode: true
          namespace: kube-system
          selector: k8s-app=kube-scheduler
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10259
          matchNode: true
          namespace: kube-system
          selector: app=openshift-kube-scheduler,scheduler=true
        enabled: true
      controllerManager:
        autodiscover:
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10257
          matchNode: true
          namespace: kube-system
          selector: tier=control-plane,component=kube-controller-manager
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10257
          matchNode: true
          namespace: kube-system
          selector: k8s-app=kube-controller-manager
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10257
          matchNode: true
          namespace: kube-system
          selector: app=kube-controller-manager,kube-controller-manager=true
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:10257
          matchNode: true
          namespace: kube-system
          selector: app=controller-manager,controller-manager=true
        enabled: true
      apiServer:
        autodiscover:
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:8443
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:6443
          - url: http://localhost:8080
          matchNode: true
          namespace: kube-system
          selector: tier=control-plane,component=kube-apiserver
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:8443
          - url: http://localhost:8080
          matchNode: true
          namespace: kube-system
          selector: k8s-app=kube-apiserver
        - endpoints:
          - auth:
              type: bearer
            insecureSkipVerify: true
            url: https://localhost:8443
          matchNode: true
          namespace: kube-system
          selector: app=openshift-kube-apiserver,apiserver=true
        enabled: true

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/ksm/agent-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-agent-ksm
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  newrelic-infra.yml: |-
    # This is the configuration file for the infrastructure agent. See:
    # https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/
    custom_attributes:
      clusterName: k8s-cluster-name
    http_server_enabled: true
    http_server_port: 8002
    is_forward_only: true

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/ksm/scraper-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-ksm
  namespace: newrelic
data:
  nri-kubernetes.yml: |-
    interval: 20s # Default value is 15s
    ksm:
      enabled: true
      retries: 3
      scheme: http
      selector: app.kubernetes.io/name=kube-state-metrics
      timeout: 10s

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/kubelet/agent-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-agent-kubelet
data:
  # In case of making any changes to this file it should be added to corresponding patch listed in these files:
  # - ping-cloud-base/code-gen/templates/common/base/cluster-tools/monitoring/kustomization.yaml
  # - ping-cloud-base/dev-cluster-state/cluster-tools/kustomization.yaml
  newrelic-infra.yml: |-
    # This is the configuration file for the infrastructure agent. See:
    # https://docs.newrelic.com/docs/infrastructure/install-infrastructure-agent/configuration/infrastructure-agent-configuration-settings/
    custom_attributes:
      clusterName: k8s-cluster-name
    features:
      docker_enabled: false
    http_server_enabled: true
    http_server_port: 8003

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/kubelet/integrations-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-integrations-cfg
data:
  # This ConfigMap holds config files for integrations. They should have the following format:
  #redis-config.yml: |
  #  # Run auto discovery to find pods with label "app=redis"
  #  discovery:
  #    command:
  #      # Run discovery for Kubernetes. Use the following optional arguments:
  #      # --namespaces: Comma separated list of namespaces to discover pods on
  #      # --tls: Use secure (TLS) connection
  #      # --port: Port used to connect to the kubelet. Default is 10255
  #      exec: /var/db/newrelic-infra/nri-discovery-kubernetes --port PORT --tls
  #      match:
  #        label.app: redis
  #  integrations:
  #    - name: nri-redis
  #      env:
  #        # using the discovered IP as the hostname address
  #        HOSTNAME: ${discovery.ip}
  #        PORT: 6379
  #        KEYS: '{"0":["<KEY_1>"],"1":["<KEY_2>"]}'
  #        REMOTE_MONITORING: true
  #      labels:
  #        env: production
  
  pixie-health-check.yaml: |
    ---
    # This Flex config performs periodic checks of the Pixie
    # /healthz and /statusz endpoints exposed by the Pixie Cloud Connector.
    # A status for each endpoint is sent to New Relic in a pixieHealthCheck event.
    #
    # If Pixie is not installed in the cluster, no events will be generated.
    # This can also be disabled with enablePixieHealthCheck: false in the values.yaml file.
    discovery:
      command:
        exec: /var/db/newrelic-infra/nri-discovery-kubernetes --tls --port 10250
        match:
          label.name: vizier-cloud-connector
    integrations:
      - name: nri-flex
        interval: 60s
        config:
          name: pixie-health-check
          apis:
            - event_type: pixieHealth
              commands:
                - run: curl --insecure -s https://${discovery.ip}:50800/healthz | xargs | awk '{print "cloud_connector_health:"$1}'
                  split_by: ":"
              merge: pixieHealthCheck
            - event_type: pixieStatus
              commands:
                - run: curl --insecure -s https://${discovery.ip}:50800/statusz | awk '{if($1 == ""){ print "cloud_connector_status:OK" } else { print "cloud_connector_status:"$1 }}'
                  split_by: ":"
              merge: pixieHealthCheck

---
# New Relic Pingmetadata Integration

apiVersion: v1
kind: ConfigMap
metadata:
  name: pingmetadata
  namespace: newrelic
data:
  pingmetadata.yaml: |
    ---
    integrations:
      - name: nri-flex
        # interval: 30s
        config:
          name: pingmetadata
          apis:
            - name: pingmetaDataOutput
              commands:
                # run any command, you could cat .json file, or run some commands that produce a json output
                # the example just calls an API that returns json
                - run: curl -sk https://metadata.${cde}-${customer}.${region}.${stage}.cloud #json output is retrieved from this command
              custom_attributes:
                pingCloudVersion: version

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/kubelet/scraper-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-kubelet
  namespace: newrelic
data:
  nri-kubernetes.yml: |
    interval: 20s # Default value is 15s
    kubelet:
      enabled: true
      retries: 3
      timeout: 10s

---
# Script to provision NewRelic secrets

apiVersion: v1
kind: ConfigMap
metadata:
  name: copy-secret
  namespace: newrelic
data:
  copy-secret.sh: |-
    #!/bin/sh

    cd /tmp

    kubectl get secret ${SECRET_NAME} \
        -n ${SECRET_NAMESPACE} \
        -o jsonpath='{.data.NEW_RELIC_LICENSE_KEY}' |
    base64 -d > NEW_RELIC_LICENSE_KEY

    kubectl create secret generic ${SECRET_NAME} \
        -n ${CURRENT_NAMESPACE} \
        --from-file=NEW_RELIC_LICENSE_KEY

    rm -f NEW_RELIC_LICENSE_KEY

---
# Source: nri-bundle/charts/nri-kube-events/templates/agent-configmap.yaml

apiVersion: v1
kind: ConfigMap
metadata:
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-kube-events
    app.kubernetes.io/version: 1.8.0
    helm.sh/chart: nri-kube-events-2.2.4
  name: nri-bundle-nri-kube-events-agent-config
  namespace: newrelic
data:
  newrelic-infra.yml: |
    is_forward_only: true
    http_server_enabled: true
    http_server_port: 8001
---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/controlplane/daemonset.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-controlplane
spec:
  updateStrategy: 
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: nri-bundle
      app.kubernetes.io/name: newrelic-infrastructure
      app.kubernetes.io/component: controlplane
  template:
    metadata:
      labels:
        nri-bundle.version: 4.5.8
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/name: newrelic-infrastructure
        app.kubernetes.io/component: controlplane
      annotations: {}
    spec:
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      serviceAccountName: nri-bundle-newrelic-infrastructure-controlplane
      initContainers:
        - name: wait-for-nr-license-secret
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/bitnami/kubectl:1.23.0
          command: [ "/bin/sh", "-c" ]
          args: [ "kubectl get secret $(SECRET_NAME) && echo 'INFO: NR secret object found, skipping waiting for job completion.' || kubectl wait --for=condition=Complete --timeout=$(WAIT_TIMEOUT_SEC)s job/$(JOB_NAME)" ]
          env:
            - name: "WAIT_TIMEOUT_SEC"
              value: "300"
            - name: "JOB_NAME"
              value: "newrelic-license-secret-exporter"
            - name: "SECRET_NAME"
              value: "newrelic-license-key"
      containers:
        - name: controlplane
          image: public.ecr.aws/r2h3l6e4/pingcloud-monitoring/nri-kubernetes/dev:v1.18-release-branch-latest
          imagePullPolicy: Always
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          env:
            - name: "NRI_KUBERNETES_SINK_HTTP_PORT"
              value: "8001"
            - name: "NRI_KUBERNETES_CLUSTERNAME"
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['CLUSTER_NAME']
            - name: "NRI_KUBERNETES_VERBOSE"
              value: "false"

            - name: "NRI_KUBERNETES_NODENAME"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
            - name: "NRI_KUBERNETES_NODEIP"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "status.hostIP"
          volumeMounts:
            - name: nri-kubernetes-config
              mountPath: /etc/newrelic-infra/nri-kubernetes.yml
              subPath: nri-kubernetes.yml
          resources: 
            limits:
              memory: 300M
            requests:
              cpu: 100m
              memory: 150M
        - name: forwarder
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/newrelic/k8s-events-forwarder:1.24.1
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          ports:
            - containerPort: 8001
          env:
            - name: "NRIA_LICENSE_KEY"
              valueFrom:
                secretKeyRef:
                  name: newrelic-license-key
                  key: NEW_RELIC_LICENSE_KEY

            - name: "NRIA_OVERRIDE_HOSTNAME_SHORT"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"

            - name: "K8S_NODE_NAME"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
          volumeMounts:
            - mountPath: /var/db/newrelic-infra/data
              name: forwarder-tmpfs-data
            - mountPath: /var/db/newrelic-infra/user_data
              name: forwarder-tmpfs-user-data
            - mountPath: /tmp
              name: forwarder-tmpfs-tmp
            - name: config
              mountPath: /etc/newrelic-infra.yml
              subPath: newrelic-infra.yml
          resources: 
            limits:
              memory: 300M
            requests:
              cpu: 100m
              memory: 150M
      volumes:
        - name: nri-kubernetes-config
          configMap:
            name: nri-bundle-nrk8s-controlplane
            items:
              - key: nri-kubernetes.yml
                path: nri-kubernetes.yml
        - name: forwarder-tmpfs-data
          emptyDir: {}
        - name: forwarder-tmpfs-user-data
          emptyDir: {}
        - name: forwarder-tmpfs-tmp
          emptyDir: {}
        - name: config
          configMap:
            name: nri-bundle-nrk8s-agent-controlplane
            items:
              - key: newrelic-infra.yml
                path: newrelic-infra.yml
      affinity:
        nodeAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            nodeSelectorTerms:
            - matchExpressions:
              - key: node-role.kubernetes.io/control-plane
                operator: Exists
            - matchExpressions:
              - key: node-role.kubernetes.io/controlplane
                operator: Exists
            - matchExpressions:
              - key: node-role.kubernetes.io/etcd
                operator: Exists
            - matchExpressions:
              - key: node-role.kubernetes.io/controlplane
                operator: Exists
      tolerations:
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/kubelet/daemonset.yaml

apiVersion: apps/v1
kind: DaemonSet
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-kubelet
spec:
  updateStrategy: 
    rollingUpdate:
      maxUnavailable: 1
    type: RollingUpdate
  selector:
    matchLabels:
      app.kubernetes.io/instance: nri-bundle
      app.kubernetes.io/name: newrelic-infrastructure
      app.kubernetes.io/component: kubelet
  template:
    metadata:
      labels:
        nri-bundle.version: 4.5.8
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/name: newrelic-infrastructure
        app.kubernetes.io/component: kubelet
      annotations: {}
    spec:
      serviceAccountName: nri-bundle-newrelic-infrastructure
      hostNetwork: false
      dnsPolicy: ClusterFirstWithHostNet
      initContainers:
        - name: wait-for-nr-license-secret
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/bitnami/kubectl:1.23.0
          command: [ "/bin/sh", "-c" ]
          args: [ "kubectl get secret $(SECRET_NAME) && echo 'INFO: NR secret object found, skipping waiting for job completion.' || kubectl wait --for=condition=Complete --timeout=$(WAIT_TIMEOUT_SEC)s job/$(JOB_NAME)" ]
          env:
            - name: "WAIT_TIMEOUT_SEC"
              value: "300"
            - name: "JOB_NAME"
              value: "newrelic-license-secret-exporter"
            - name: "SECRET_NAME"
              value: "newrelic-license-key"
      containers:
        - name: kubelet
          image: public.ecr.aws/r2h3l6e4/pingcloud-monitoring/nri-kubernetes/dev:v1.18-release-branch-latest
          imagePullPolicy: Always
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          env:
            - name: "NRI_KUBERNETES_SINK_HTTP_PORT"
              value: "8003"
            - name: "NRI_KUBERNETES_CLUSTERNAME"
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['CLUSTER_NAME']
            - name: "NRI_KUBERNETES_VERBOSE"
              value: "false"

            - name: "NRI_KUBERNETES_NODENAME"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
            # Required to connect to the kubelet
            - name: "NRI_KUBERNETES_NODEIP"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "status.hostIP"
          volumeMounts:
            - name: nri-kubernetes-config
              mountPath: /etc/newrelic-infra/nri-kubernetes.yml
              subPath: nri-kubernetes.yml
          resources: 
            limits:
              memory: 300M
            requests:
              cpu: 100m
              memory: 150M
        - name: agent
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/newrelic/infrastructure-bundle:2.8.15
          args: [ "newrelic-infra" ]
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: true
            runAsGroup: 0
            runAsUser: 0
            runAsNonRoot: false
            allowPrivilegeEscalation: true
            readOnlyRootFilesystem: true
          ports:
            - containerPort: 8003
          env:
            - name: NRIA_LICENSE_KEY
              valueFrom:
                secretKeyRef:
                  name: newrelic-license-key
                  key: NEW_RELIC_LICENSE_KEY
            - name: "CLUSTER_NAME"
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['CLUSTER_NAME']
            - name: "NRIA_HOST"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "status.hostIP"
            - name: "NRIA_OVERRIDE_HOSTNAME_SHORT"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
            - name: "NRI_KUBERNETES_NODE_NAME"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
            - name: "NRIA_CUSTOM_ATTRIBUTES"
              value: '{"clusterName":"$(CLUSTER_NAME)"}'
            - name: "NRIA_PASSTHROUGH_ENVIRONMENT"
              value: "KUBERNETES_SERVICE_HOST,KUBERNETES_SERVICE_PORT,CLUSTER_NAME,CADVISOR_PORT,NRK8S_NODE_NAME,KUBE_STATE_METRICS_URL,KUBE_STATE_METRICS_POD_LABEL,TIMEOUT,ETCD_TLS_SECRET_NAME,ETCD_TLS_SECRET_NAMESPACE,API_SERVER_SECURE_PORT,KUBE_STATE_METRICS_SCHEME,KUBE_STATE_METRICS_PORT,KUBE_STATE_METRICS_NAMESPACE,SCHEDULER_ENDPOINT_URL,ETCD_ENDPOINT_URL,CONTROLLER_MANAGER_ENDPOINT_URL,API_SERVER_ENDPOINT_URL,DISABLE_KUBE_STATE_METRICS,DISCOVERY_CACHE_TTL"
          volumeMounts:
            - name: config
              mountPath: /etc/newrelic-infra.yml
              subPath: newrelic-infra.yml
            - name: nri-integrations-cfg-volume
              mountPath: /etc/newrelic-infra/integrations.d/
            - name: dev
              mountPath: /dev
            - name: host-docker-socket
              mountPath: /var/run/docker.sock
            - name: log
              mountPath: /var/log
            - name: host-volume
              mountPath: /host
              readOnly: true
            # Volume Mount added for custom defintion file used to set scrape interval
            # - mountPath: /var/db/newrelic-infra/newrelic-integrations/nri-kubernetes-definition.yml
            #   name: nri-kubernetes-definition-cfg-volume
            #   subPath: nri-kubernetes-definition.yml
            - mountPath: /var/db/newrelic-infra/data
              name: agent-tmpfs-data
            - mountPath: /var/db/newrelic-infra/user_data
              name: agent-tmpfs-user-data
            - mountPath: /tmp
              name: agent-tmpfs-tmp
          resources: 
            limits:
              memory: 300M
            requests:
              cpu: 100m
              memory: 150M
      volumes:
        - name: dev
          hostPath:
            path: /dev
        - name: host-docker-socket
          hostPath:
            path: /var/run/docker.sock
        - name: log
          hostPath:
            path: /var/log
        - name: host-volume
          hostPath:
            path: /
        # Volume added for custom defintion file used to set scrape interval
        # - name: nri-kubernetes-definition-cfg-volume
        #   configMap:
        #     name: nri-kubernetes-definition-cfg
        - name: agent-tmpfs-data
          emptyDir: {}
        - name: agent-tmpfs-user-data
          emptyDir: {}
        - name: agent-tmpfs-tmp
          emptyDir: {}
        - name: nri-kubernetes-config
          configMap:
            name: nri-bundle-nrk8s-kubelet
            items:
              - key: nri-kubernetes.yml
                path: nri-kubernetes.yml
        - name: config
          configMap:
            name: nri-bundle-nrk8s-agent-kubelet
            items:
              - key: newrelic-infra.yml
                path: newrelic-infra.yml
        - name: nri-integrations-cfg-volume
          configMap:
            name: nri-bundle-nrk8s-integrations-cfg
      tolerations:
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists

---
# Source: nri-bundle/charts/kube-state-metrics/templates/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-kube-state-metrics
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/name: kube-state-metrics
    helm.sh/chart: "kube-state-metrics-2.13.2"
    app.kubernetes.io/instance: "nri-bundle"
    app.kubernetes.io/managed-by: "Helm"
    app.kubernetes.io/version: "1.9.8"
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: kube-state-metrics
  replicas: 1
  template:
    metadata:
      labels:
        nri-bundle.version: 4.5.8
        app.kubernetes.io/name: kube-state-metrics
        app.kubernetes.io/instance: "nri-bundle"
    spec:
      hostNetwork: false
      serviceAccountName: nri-bundle-kube-state-metrics
      securityContext:
        fsGroup: 65534
        runAsGroup: 65534
        runAsUser: 65534
      containers:
      - name: kube-state-metrics
        args:
        - --collectors=certificatesigningrequests
        - --collectors=configmaps
        - --collectors=cronjobs
        - --collectors=daemonsets
        - --collectors=deployments
        - --collectors=endpoints
        - --collectors=horizontalpodautoscalers
        - --collectors=ingresses
        - --collectors=jobs
        - --collectors=limitranges
        - --collectors=mutatingwebhookconfigurations
        - --collectors=namespaces
        - --collectors=networkpolicies
        - --collectors=nodes
        - --collectors=persistentvolumeclaims
        - --collectors=persistentvolumes
        - --collectors=poddisruptionbudgets
        - --collectors=pods
        - --collectors=replicasets
        - --collectors=replicationcontrollers
        - --collectors=resourcequotas
        - --collectors=secrets
        - --collectors=services
        - --collectors=statefulsets
        - --collectors=storageclasses
        - --collectors=validatingwebhookconfigurations
        - --collectors=volumeattachments
        - --telemetry-port=8081
        imagePullPolicy: IfNotPresent
        image: k8s.gcr.io/kube-state-metrics/kube-state-metrics:v1.9.8
        securityContext:
          privileged: false
          runAsGroup: 65534
          runAsUser: 65534
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
        ports:
        - containerPort: 8080
        livenessProbe:
          httpGet:
            path: /healthz
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5
        readinessProbe:
          httpGet:
            path: /
            port: 8080
          initialDelaySeconds: 5
          timeoutSeconds: 5

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-nri-metadata-injection
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-metadata-injection
    app.kubernetes.io/version: 1.7.0
    helm.sh/chart: nri-metadata-injection-3.0.4
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nri-metadata-injection
  template:
    metadata:
      labels:
        nri-bundle.version: 4.5.8
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/name: nri-metadata-injection
        app.kubernetes.io/version: 1.7.0
        helm.sh/chart: nri-metadata-injection-3.0.4
      annotations: {}
    spec:
      # Switching from dedicated service account to default one must be
      # done explicitly, otherwise upgrade fails, trying to use old
      # service account.
      serviceAccount: default
      securityContext:
        fsGroup: 1001
        runAsUser: 1001
        runAsGroup: 1001
      hostNetwork: false
      containers:
      - name: nri-metadata-injection
        image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/newrelic/k8s-metadata-injection:1.7.0
        imagePullPolicy: IfNotPresent
        securityContext:
          privileged: false
          runAsUser: 1001
          runAsGroup: 1001
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
        env:
        - name: clusterName
          valueFrom:
            fieldRef:
              fieldPath: metadata.annotations['clusterName']
        ports:
          - containerPort: 8443
            protocol: TCP
        volumeMounts:
        - name: tls-key-cert-pair
          mountPath: /etc/tls-key-cert-pair
        readinessProbe:
          httpGet:
            path: /health
            port: 8080
          initialDelaySeconds: 1
          periodSeconds: 1
        resources:
          
          limits:
            memory: 80M
          requests:
            cpu: 100m
            memory: 30M
      volumes:
      - name: tls-key-cert-pair
        secret:
          secretName: nri-bundle-nri-metadata-injection-admission

---
# Source: nri-bundle/charts/nri-prometheus/templates/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-nri-prometheus
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-prometheus
    app.kubernetes.io/version: 2.16.1
    helm.sh/chart: nri-prometheus-2.1.5
spec:
  replicas: 1
  selector:
    matchLabels:
      app.kubernetes.io/name: nri-prometheus
  template:
    metadata:
      annotations:
        checksum/config: ccb1eaf63851097c4abf7fd036baccf66b0979e728f14bbe687d21a691119c17
      labels:
        nri-bundle.version: 4.5.8
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/name: nri-prometheus
    spec:
      serviceAccountName: nri-bundle-nri-prometheus
      initContainers:
        - name: wait-for-nr-license-secret
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/bitnami/kubectl:1.23.0
          command: [ "/bin/sh", "-c" ]
          args: [ "kubectl get secret $(SECRET_NAME) && echo 'INFO: NR secret object found, skipping waiting for job completion.' || kubectl wait --for=condition=Complete --timeout=$(WAIT_TIMEOUT_SEC)s job/$(JOB_NAME)" ]
          env:
            - name: "WAIT_TIMEOUT_SEC"
              value: "300"
            - name: "JOB_NAME"
              value: "newrelic-license-secret-exporter"
            - name: "SECRET_NAME"
              value: "newrelic-license-key"
      containers:
      - name: nri-prometheus
        image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/newrelic/nri-prometheus:2.16.1
        imagePullPolicy: IfNotPresent
        securityContext:
          privileged: false
          runAsGroup: 65534
          runAsUser: 65534
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
        args:
          - "--configfile=/etc/nri-prometheus/config.yaml"
        ports:
          - containerPort: 8080
        volumeMounts:
        - name: config-volume
          mountPath: /etc/nri-prometheus/
        env:
          - name: "LICENSE_KEY"
            valueFrom:
              secretKeyRef:
                name: newrelic-license-key
                key: NEW_RELIC_LICENSE_KEY
          - name: "BEARER_TOKEN_FILE"
            value: "/var/run/secrets/kubernetes.io/serviceaccount/token"
          - name: "CA_FILE"
            value: "/var/run/secrets/kubernetes.io/serviceaccount/ca.crt"
      volumes:
        - name: config-volume
          configMap:
            name: nri-bundle-nri-prometheus-config

---
# Source: nri-bundle/charts/nri-kube-events/templates/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  name: nri-bundle-nri-kube-events
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-kube-events
    app.kubernetes.io/version: 1.8.0
    helm.sh/chart: nri-kube-events-2.2.4
  annotations:
spec:
  selector:
    matchLabels:
      app.kubernetes.io/name: nri-kube-events
  template:
    metadata:
      labels:
        nri-bundle.version: 4.5.8
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/name: nri-kube-events
        app.kubernetes.io/version: 1.8.0
        helm.sh/chart: nri-kube-events-2.2.4
    spec:
      hostNetwork: true
      securityContext:
        runAsNonRoot: true
        runAsUser: 1000
      initContainers:
        - name: wait-for-nr-license-secret
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/bitnami/kubectl:1.23.0
          command: [ "/bin/sh", "-c" ]
          args: [ "kubectl get secret $(SECRET_NAME) && echo 'INFO: NR secret object found, skipping waiting for job completion.' || kubectl wait --for=condition=Complete --timeout=$(WAIT_TIMEOUT_SEC)s job/$(JOB_NAME)" ]
          env:
            - name: "WAIT_TIMEOUT_SEC"
              value: "300"
            - name: "JOB_NAME"
              value: "newrelic-license-secret-exporter"
            - name: "SECRET_NAME"
              value: "newrelic-license-key"
      containers:
        - name: kube-events
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/newrelic/nri-kube-events:1.8.0
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          args: ["-config", "/app/config/config.yaml", "-loglevel", "debug"]
          volumeMounts:
            - name: config-volume
              mountPath: /app/config
        - name: forwarder
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/newrelic/k8s-events-forwarder:1.22.0
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          ports:
            - containerPort: 8001
          env:
            - name: NRIA_LICENSE_KEY
              valueFrom:
                secretKeyRef:
                  name: newrelic-license-key
                  key: NEW_RELIC_LICENSE_KEY

            # Using FORWARD_ONLY mode to avoid the entity creation for the events.
            - name: NRIA_IS_SECURE_FORWARD_ONLY
              value: "false"
            - name: NRIA_IS_FORWARD_ONLY
              value: "true"

            - name: NRIA_OVERRIDE_HOSTNAME_SHORT
              valueFrom:
                fieldRef:
                  apiVersion: v1
                  fieldPath: spec.nodeName

          volumeMounts:
            - mountPath: /var/db/newrelic-infra/data
              name: tmpfs-data
            - mountPath: /var/db/newrelic-infra/user_data
              name: tmpfs-user-data
            - mountPath: /tmp
              name: tmpfs-tmp
            - name: config
              mountPath: /etc/newrelic-infra.yml
              subPath: newrelic-infra.yml
            - name: pingmetadata
              mountPath: /etc/newrelic-infra/integrations.d
      serviceAccountName: nri-bundle-nri-kube-events
      volumes:
        - name: config
          configMap:
            name: nri-bundle-nri-kube-events-agent-config
            items:
            - key: newrelic-infra.yml
              path: newrelic-infra.yml
        - name: config-volume
          configMap:
            name: nri-bundle-nri-kube-events-config
        - name: tmpfs-data
          emptyDir: {}
        - name: tmpfs-user-data
          emptyDir: {}
        - name: tmpfs-tmp
          emptyDir: {}
        - name: pingmetadata
          configMap:
            name: pingmetadata
            items:
              - key: "pingmetadata.yaml"
                path: "pingmetadata.yaml"

---
# Source: nri-bundle/charts/newrelic-infrastructure/templates/ksm/deployment.yaml

apiVersion: apps/v1
kind: Deployment
metadata:
  namespace: newrelic
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: newrelic-infrastructure
    app.kubernetes.io/version: 3.2.0
    helm.sh/chart: newrelic-infrastructure-3.5.3
  name: nri-bundle-nrk8s-ksm
spec:
  strategy: 
    type: Recreate
  selector:
    matchLabels:
      app.kubernetes.io/instance: nri-bundle
      app.kubernetes.io/name: newrelic-infrastructure
      app.kubernetes.io/component: ksm
  template:
    metadata:
      labels:
        nri-bundle.version: 4.5.8
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/name: newrelic-infrastructure
        app.kubernetes.io/component: ksm
      annotations: {}
    spec:
      serviceAccountName: nri-bundle-newrelic-infrastructure
      hostNetwork: true
      dnsPolicy: ClusterFirstWithHostNet
      initContainers:
        - name: wait-for-nr-license-secret
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/bitnami/kubectl:1.23.0
          command: [ "/bin/sh", "-c" ]
          args: [ "kubectl get secret $(SECRET_NAME) && echo 'INFO: NR secret object found, skipping waiting for job completion.' || kubectl wait --for=condition=Complete --timeout=$(WAIT_TIMEOUT_SEC)s job/$(JOB_NAME)" ]
          env:
            - name: "WAIT_TIMEOUT_SEC"
              value: "300"
            - name: "JOB_NAME"
              value: "newrelic-license-secret-exporter"
            - name: "SECRET_NAME"
              value: "newrelic-license-key"
      containers:
        - name: ksm
          image: public.ecr.aws/r2h3l6e4/pingcloud-monitoring/nri-kubernetes/dev:v1.18-release-branch-latest
          imagePullPolicy: Always
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          env:
            - name: "NRI_KUBERNETES_SINK_HTTP_PORT"
              value: "8002"
            - name: "NRI_KUBERNETES_CLUSTERNAME"
              valueFrom:
                fieldRef:
                  fieldPath: metadata.annotations['CLUSTER_NAME']
            - name: "NRI_KUBERNETES_VERBOSE"
              value: "false"

            - name: "NRI_KUBERNETES_NODENAME"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
          volumeMounts:
            - name: nri-kubernetes-config
              mountPath: /etc/newrelic-infra/nri-kubernetes.yml
              subPath: nri-kubernetes.yml
            - name: pingmetadata
              mountPath: /etc/newrelic-infra/integrations.d
          resources: 
            limits:
              memory: 850M
            requests:
              cpu: 100m
              memory: 150M
        - name: forwarder
          image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/newrelic/k8s-events-forwarder:1.24.1
          imagePullPolicy: IfNotPresent
          securityContext:
            privileged: false
            runAsGroup: 2000
            runAsUser: 1000
            runAsNonRoot: true
            allowPrivilegeEscalation: false
            readOnlyRootFilesystem: true
          ports:
            - containerPort: 8002
          env:
            - name: NRIA_LICENSE_KEY
              valueFrom:
                secretKeyRef:
                  name: newrelic-license-key
                  key: NEW_RELIC_LICENSE_KEY
            - name: "NRIA_OVERRIDE_HOSTNAME_SHORT"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
            - name: "K8S_NODE_NAME"
              valueFrom:
                fieldRef:
                  apiVersion: "v1"
                  fieldPath: "spec.nodeName"
            - name: "NRIA_CUSTOM_ATTRIBUTES"
              value: '{"clusterName":"$(CLUSTER_NAME)"}'
            - name: "NRIA_PASSTHROUGH_ENVIRONMENT"
              value: "KUBERNETES_SERVICE_HOST,KUBERNETES_SERVICE_PORT,CLUSTER_NAME,CADVISOR_PORT,NRK8S_NODE_NAME,KUBE_STATE_METRICS_URL,KUBE_STATE_METRICS_POD_LABEL,TIMEOUT,ETCD_TLS_SECRET_NAME,ETCD_TLS_SECRET_NAMESPACE,API_SERVER_SECURE_PORT,KUBE_STATE_METRICS_SCHEME,KUBE_STATE_METRICS_PORT,SCHEDULER_ENDPOINT_URL,ETCD_ENDPOINT_URL,CONTROLLER_MANAGER_ENDPOINT_URL,API_SERVER_ENDPOINT_URL,DISABLE_KUBE_STATE_METRICS,DISCOVERY_CACHE_TTL"
          volumeMounts:
            - mountPath: /var/db/newrelic-infra/data
              name: forwarder-tmpfs-data
            - mountPath: /var/db/newrelic-infra/user_data
              name: forwarder-tmpfs-user-data
            - mountPath: /tmp
              name: forwarder-tmpfs-tmp
            - name: config
              mountPath: /etc/newrelic-infra.yml
              subPath: newrelic-infra.yml
            - name: pingmetadata
              mountPath: /etc/newrelic-infra/integrations.d
          resources: 
            limits:
              memory: 850M
            requests:
              cpu: 100m
              memory: 150M
      volumes:
        - name: nri-kubernetes-config
          configMap:
            name: nri-bundle-nrk8s-ksm
            items:
              - key: nri-kubernetes.yml
                path: nri-kubernetes.yml
        - name: forwarder-tmpfs-data
          emptyDir: {}
        - name: forwarder-tmpfs-user-data
          emptyDir: {}
        - name: forwarder-tmpfs-tmp
          emptyDir: {}
        - name: config
          configMap:
            name: nri-bundle-nrk8s-agent-ksm
            items:
              - key: newrelic-infra.yml
                path: newrelic-infra.yml
        - name: pingmetadata
          configMap:
            name: pingmetadata
            items:
              - key: "pingmetadata.yaml"
                path: "pingmetadata.yaml"
      affinity:
        podAffinity:
          preferredDuringSchedulingIgnoredDuringExecution:
          - podAffinityTerm:
              labelSelector:
                matchLabels:
                  app.kubernetes.io/name: kube-state-metrics
              topologyKey: kubernetes.io/hostname
            weight: 100
      tolerations:
        - effect: NoSchedule
          operator: Exists
        - effect: NoExecute
          operator: Exists
---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/job-createSecret.yaml

apiVersion: batch/v1
kind: Job
metadata:
  name: nri-bundle-nri-metadata-injection-admission-create
  namespace: newrelic
  annotations:
    argocd.argoproj.io/hook: Sync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation,HookSucceeded
  labels:
    nri-bundle.version: 4.5.8
    app: nri-metadata-injection-admission-create
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-metadata-injection
    app.kubernetes.io/version: 1.7.0
    helm.sh/chart: nri-metadata-injection-3.0.4
spec:
  ttlSecondsAfterFinished: 30
  template:
    metadata:
      name: nri-bundle-nri-metadata-injection-admission-create
      labels:
        nri-bundle.version: 4.5.8
        app: nri-metadata-injection-admission-create
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/name: nri-metadata-injection
        app.kubernetes.io/version: 1.7.0
        helm.sh/chart: nri-metadata-injection-3.0.4
    spec:
      containers:
        - name: create
          image: k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1
          imagePullPolicy: IfNotPresent
          args:
            - create
            - --host=nri-bundle-nri-metadata-injection,nri-bundle-nri-metadata-injection.newrelic.svc
            - --namespace=newrelic
            - --secret-name=nri-bundle-nri-metadata-injection-admission
            - --cert-name=tls.crt
            - --key-name=tls.key
      restartPolicy: OnFailure
      serviceAccountName: nri-bundle-nri-metadata-injection-admission
      securityContext:
        runAsGroup: 2000
        runAsUser: 2000
        runAsNonRoot: true

---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/job-patch/job-patchWebhook.yaml

apiVersion: batch/v1
kind: Job
metadata:
  name: nri-bundle-nri-metadata-injection-admission-patch
  namespace: newrelic
  annotations:
    argocd.argoproj.io/hook: PostSync
    argocd.argoproj.io/hook-delete-policy: BeforeHookCreation,HookSucceeded
  labels:
    nri-bundle.version: 4.5.8
    app: nri-metadata-injection-admission-patch
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-metadata-injection
    app.kubernetes.io/version: 1.7.0
    helm.sh/chart: nri-metadata-injection-3.0.4
spec:
  ttlSecondsAfterFinished: 30
  template:
    metadata:
      name: nri-bundle-nri-metadata-injection-admission-patch
      labels:
        nri-bundle.version: 4.5.8
        app: nri-metadata-injection-admission-patch
        app.kubernetes.io/instance: nri-bundle
        app.kubernetes.io/name: nri-metadata-injection
        app.kubernetes.io/version: 1.7.0
        helm.sh/chart: nri-metadata-injection-3.0.4
    spec:
      containers:
        - name: patch
          image: k8s.gcr.io/ingress-nginx/kube-webhook-certgen:v1.1.1
          imagePullPolicy: IfNotPresent
          args:
            - patch
            - --webhook-name=nri-bundle-nri-metadata-injection
            - --namespace=newrelic
            - --secret-name=nri-bundle-nri-metadata-injection-admission
            - --patch-failure-policy=Ignore
            - --patch-validating=false
      restartPolicy: OnFailure
      serviceAccountName: nri-bundle-nri-metadata-injection-admission
      securityContext:
        runAsGroup: 2000
        runAsUser: 2000
        runAsNonRoot: true

---
# This job copies NR License key secret object to 'newrelic' namespace

apiVersion: batch/v1
kind: Job
metadata:
  name: newrelic-license-secret-exporter
  namespace: newrelic
  labels:
    app: newrelic-license-secret-exporter
  annotations:
    argocd.argoproj.io/hook: Sync
spec:
  ttlSecondsAfterFinished: 30
  template:
    metadata:
      labels:
        app: newrelic-license-secret-exporter
      annotations: {}
    spec:
      restartPolicy: OnFailure
      serviceAccountName: nri-bundle-newrelic-infrastructure
      volumes:
        - name: copy-secret
          configMap:
            name: copy-secret
            defaultMode: 0555
      containers:
      - name: newrelic-license-secret-exporter
        securityContext:
          runAsGroup: 2000
          runAsNonRoot: true
          runAsUser: 1000
          allowPrivilegeEscalation: false
        image: public.ecr.aws/r2h3l6e4/pingcloud-clustertools/bitnami/kubectl:1.23.0
        command:
          - /tmp/copy-secret.sh
        env:
          - name: "SECRET_NAME"
            value: "newrelic-license-key"
          - name: "SECRET_NAMESPACE"
            valueFrom:
              fieldRef:
                fieldPath: metadata.annotations['SECRET_NAMESPACE']
          - name: "CURRENT_NAMESPACE"
            valueFrom:
              fieldRef:
                fieldPath: metadata.namespace
        volumeMounts:
          - name: copy-secret
            mountPath: /tmp/copy-secret.sh
            subPath: copy-secret.sh
---
# Source: nri-bundle/charts/nri-metadata-injection/templates/admission-webhooks/mutatingWebhookConfiguration.yaml

apiVersion: admissionregistration.k8s.io/v1
kind: MutatingWebhookConfiguration
metadata:
  name: nri-bundle-nri-metadata-injection
  labels:
    nri-bundle.version: 4.5.8
    app.kubernetes.io/instance: nri-bundle
    app.kubernetes.io/name: nri-metadata-injection
    app.kubernetes.io/version: 1.7.0
    helm.sh/chart: nri-metadata-injection-3.0.4
webhooks:
- name: metadata-injection.newrelic.com
  clientConfig:
    service:
      name: nri-bundle-nri-metadata-injection
      namespace: newrelic
      path: "/mutate"
    caBundle: ""
  rules:
  - operations: ["CREATE"]
    apiGroups: [""]
    apiVersions: ["v1"]
    resources: ["pods"]
  failurePolicy: Ignore
  timeoutSeconds: 30
  sideEffects: None
  admissionReviewVersions:
  - v1beta1
  - v1
kind: Namespace
apiVersion: v1
metadata:
  name: newrelic
  annotations:
    argocd.argoproj.io/sync-wave: "-1"
  labels:
    pod-security.kubernetes.io/enforce: privileged
    pod-security.kubernetes.io/enforce-version: latest